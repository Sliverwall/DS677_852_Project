{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb0a0c0",
   "metadata": {},
   "source": [
    "# Transcribe_audio notebook\n",
    "\n",
    "## Purpose\n",
    "---\n",
    "- Uses openai's whisper-large-v3 model to take sample audio files, then automate the transcription process.\n",
    "- Coqui-Ai XTTS fine-tuning process requires a text-transcription for each audio file. If an audio sample does not have this, it would be difficult to write, by hand, the text needed.\n",
    "- Will be used when annotating speech from personal audio samples as well.\n",
    "---\n",
    "\n",
    "## How to use\n",
    "---\n",
    "- Requires torch and HuggingFace's transformers API to use the whisper-large-v3 model.\n",
    "- Define an import dir path where all your .wav audio files exist. \n",
    "- Define an output path for a csv file. Here, as each audio file is transcribed, its file-name and transcription will be written to the output CSV. This can be used as the metadata file for the fine-tuning process.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e32938",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Requires FFMEG to be installed for whipser model'''\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a747a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "'''Load in whipster model using transformers api'''\n",
    "# Set device and torch data type\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(device)\n",
    "\n",
    "# Define chunk size used in seconds\n",
    "chunkSize = 10\n",
    "\n",
    "# Model identifier\n",
    "model_id = \"openai/whisper-large-v3\" # Was about 3G\n",
    "\n",
    "# Load the model and move it to the selected device\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype, \n",
    "    low_cpu_mem_usage=False, \n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(model_id, language='en')\n",
    "\n",
    "# Create the speech recognition pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=chunkSize,\n",
    "    batch_size=32, \n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0c9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step up paths for imput and output files'''\n",
    "# Define a path to an output CSV to save transcriptions\n",
    "outputPath = \"datasets/metadata.csv\"\n",
    "\n",
    "# Define where sample audio files are coming from\n",
    "audioDir = \"chunks/\"\n",
    "\n",
    "# Read in all files from chosen dir\n",
    "fileList = os.listdir(audioDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2055cda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12017\\anaconda3\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing chunk_0000.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing chunk_0001.wav...\n",
      "Transcribing chunk_0002.wav...\n",
      "Transcribing chunk_0003.wav...\n",
      "Transcribing chunk_0004.wav...\n",
      "Transcribing chunk_0005.wav...\n",
      "Transcribing chunk_0006.wav...\n",
      "Transcribing chunk_0007.wav...\n",
      "Transcribing chunk_0008.wav...\n",
      "Transcribing chunk_0009.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing chunk_0010.wav...\n",
      "Transcribing chunk_0011.wav...\n",
      "Transcribing chunk_0012.wav...\n",
      "Transcribing chunk_0013.wav...\n",
      "Transcribing chunk_0014.wav...\n",
      "Transcribing chunk_0015.wav...\n",
      "Transcribing chunk_0016.wav...\n",
      "Transcribing chunk_0017.wav...\n",
      "Transcribing chunk_0018.wav...\n",
      "Transcribing chunk_0019.wav...\n",
      "Transcribing chunk_0020.wav...\n",
      "Transcribing chunk_0021.wav...\n",
      "Transcribing chunk_0022.wav...\n",
      "Transcribing chunk_0023.wav...\n",
      "Transcribing chunk_0024.wav...\n",
      "Transcribing chunk_0025.wav...\n",
      "Transcribing chunk_0026.wav...\n",
      "Transcribing chunk_0027.wav...\n",
      "Transcribing chunk_0028.wav...\n",
      "Transcribing chunk_0029.wav...\n",
      "Transcribing chunk_0030.wav...\n",
      "Transcribing chunk_0031.wav...\n",
      "Transcribing chunk_0032.wav...\n",
      "Transcribing chunk_0033.wav...\n",
      "Transcribing chunk_0034.wav...\n",
      "Transcribing chunk_0035.wav...\n",
      "Transcribing chunk_0036.wav...\n",
      "Transcribing chunk_0037.wav...\n",
      "Transcribing chunk_0038.wav...\n",
      "Transcribing chunk_0039.wav...\n",
      "Transcribing chunk_0040.wav...\n",
      "Transcribing chunk_0041.wav...\n",
      "Transcribing chunk_0042.wav...\n",
      "Transcribing chunk_0043.wav...\n",
      "Transcribing chunk_0044.wav...\n",
      "Transcribing chunk_0045.wav...\n",
      "Transcribing chunk_0046.wav...\n",
      "Transcribing chunk_0047.wav...\n",
      "Transcribing chunk_0048.wav...\n",
      "Transcribing chunk_0049.wav...\n",
      "Transcribing chunk_0050.wav...\n",
      "Transcribing chunk_0051.wav...\n",
      "Transcribing chunk_0052.wav...\n",
      "Transcribing chunk_0053.wav...\n",
      "Transcribing chunk_0054.wav...\n",
      "Transcribing chunk_0055.wav...\n",
      "Transcribing chunk_0056.wav...\n",
      "Transcribing chunk_0057.wav...\n",
      "Transcribing chunk_0058.wav...\n",
      "Transcribing chunk_0059.wav...\n",
      "Transcribing chunk_0060.wav...\n",
      "Transcribing chunk_0061.wav...\n",
      "Transcribing chunk_0062.wav...\n",
      "Transcribing chunk_0063.wav...\n",
      "Transcribing chunk_0064.wav...\n",
      "Transcribing chunk_0065.wav...\n",
      "Transcribing chunk_0066.wav...\n",
      "Transcribing chunk_0067.wav...\n",
      "Transcribing chunk_0068.wav...\n",
      "Transcribing chunk_0069.wav...\n",
      "Transcribing chunk_0070.wav...\n",
      "Transcribing chunk_0071.wav...\n",
      "Transcribing chunk_0072.wav...\n",
      "Transcribing chunk_0073.wav...\n",
      "Transcribing chunk_0074.wav...\n",
      "Transcribing chunk_0075.wav...\n",
      "Transcribing chunk_0076.wav...\n",
      "Transcribing chunk_0077.wav...\n",
      "Transcribing chunk_0078.wav...\n",
      "Transcribing chunk_0079.wav...\n",
      "Transcribing chunk_0080.wav...\n",
      "Transcribing chunk_0081.wav...\n",
      "Transcribing chunk_0082.wav...\n",
      "Transcribing chunk_0083.wav...\n",
      "Transcribing chunk_0084.wav...\n",
      "Transcribing chunk_0085.wav...\n",
      "Transcribing chunk_0086.wav...\n",
      "Transcribing chunk_0087.wav...\n",
      "Transcribing chunk_0088.wav...\n",
      "Transcribing chunk_0089.wav...\n",
      "Transcribing chunk_0090.wav...\n",
      "Transcribing chunk_0091.wav...\n",
      "Transcribing chunk_0092.wav...\n",
      "Transcribing chunk_0093.wav...\n",
      "Transcribing chunk_0094.wav...\n",
      "Transcribing chunk_0095.wav...\n",
      "Transcribing chunk_0096.wav...\n",
      "Transcribing chunk_0097.wav...\n",
      "Transcribing chunk_0098.wav...\n",
      "Transcribing chunk_0099.wav...\n",
      "Transcribing chunk_0100.wav...\n",
      "Transcribing chunk_0101.wav...\n",
      "Transcribing chunk_0102.wav...\n",
      "Transcribing chunk_0103.wav...\n",
      "Transcribing chunk_0104.wav...\n",
      "Transcribing chunk_0105.wav...\n",
      "Transcribing chunk_0106.wav...\n",
      "Transcribing chunk_0107.wav...\n",
      "Transcribing chunk_0108.wav...\n",
      "Transcribing chunk_0109.wav...\n",
      "Transcribing chunk_0110.wav...\n",
      "Transcribing chunk_0111.wav...\n",
      "Transcribing chunk_0112.wav...\n",
      "Transcribing chunk_0113.wav...\n",
      "Transcribing chunk_0114.wav...\n",
      "Transcribing chunk_0115.wav...\n",
      "Transcribing chunk_0116.wav...\n",
      "Transcribing chunk_0117.wav...\n",
      "Transcribing chunk_0118.wav...\n",
      "Transcribing chunk_0119.wav...\n",
      "Transcribing chunk_0120.wav...\n",
      "Transcribing chunk_0121.wav...\n",
      "Transcribing chunk_0122.wav...\n",
      "Transcribing chunk_0123.wav...\n",
      "Transcribing chunk_0124.wav...\n",
      "Transcribing chunk_0125.wav...\n",
      "Transcribing chunk_0126.wav...\n",
      "Transcribing chunk_0127.wav...\n",
      "Transcribing chunk_0128.wav...\n",
      "Transcribing chunk_0129.wav...\n",
      "Transcribing chunk_0130.wav...\n",
      "Transcribing chunk_0131.wav...\n",
      "Transcribing chunk_0132.wav...\n",
      "Transcribing chunk_0133.wav...\n",
      "Transcribing chunk_0134.wav...\n",
      "Transcribing chunk_0135.wav...\n",
      "Transcribing chunk_0136.wav...\n",
      "Transcribing chunk_0137.wav...\n",
      "Transcribing chunk_0138.wav...\n",
      "Transcribing chunk_0139.wav...\n"
     ]
    }
   ],
   "source": [
    "'''Transcribe sample files'''\n",
    "# Init list to hold all samples \n",
    "samples = []\n",
    "\n",
    "'''Loop here to go through multiple .wav files if needed'''\n",
    "for i in range(len(fileList)): \n",
    "    # Specify the path to your local .wav file\n",
    "    fileName = fileList[i]\n",
    "    audioPath = audioDir + fileName\n",
    "    # Msg to show transcription is proceeding\n",
    "    print(f\"Transcribing {fileName}...\")\n",
    "    # Run the pipeline on the .wav file\n",
    "    result = pipe(audioPath)[\"text\"]\n",
    "    # LJ speech format (filename, transcript, normalised transcript)\n",
    "    samples.append((fileName.split('.')[0], result, result)) # no need to normalzied when fine-tuning. Just duplicate 2nd col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffb2a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptions written to: datasets/metadata_01.csv\n"
     ]
    }
   ],
   "source": [
    "# Write the samples list to output csv\n",
    "with open(outputPath, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    # create csv writer\n",
    "    csvWriter = csv.writer(f, delimiter='|')\n",
    "    \n",
    "    # Note: No need for headers in LJ sppech format...\n",
    "    \n",
    "    # Write each sample to the CSV file\n",
    "    for entry in samples:\n",
    "        csvWriter.writerow(entry)\n",
    "\n",
    "print(\"Transcriptions written to:\", outputPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
