2025-04-17 19:40:51,601 INFO    MainThread:19800 [wandb_setup.py:_flush():67] Current SDK version is 0.19.9
2025-04-17 19:40:51,601 INFO    MainThread:19800 [wandb_setup.py:_flush():67] Configure stats pid to 19800
2025-04-17 19:40:51,601 INFO    MainThread:19800 [wandb_setup.py:_flush():67] Loading settings from C:\Users\12017\.config\wandb\settings
2025-04-17 19:40:51,601 INFO    MainThread:19800 [wandb_setup.py:_flush():67] Loading settings from C:\Users\12017\Desktop\NJIT\DS677_852_Project\src\wandb\settings
2025-04-17 19:40:51,601 INFO    MainThread:19800 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-04-17 19:40:51,601 INFO    MainThread:19800 [wandb_init.py:setup_run_log_directory():662] Logging user logs to C:\Users\12017\Desktop\NJIT\DS677_852_Project\src\wandb\run-20250417_194051-cjyhak0p\logs\debug.log
2025-04-17 19:40:51,602 INFO    MainThread:19800 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to C:\Users\12017\Desktop\NJIT\DS677_852_Project\src\wandb\run-20250417_194051-cjyhak0p\logs\debug-internal.log
2025-04-17 19:40:51,602 INFO    MainThread:19800 [wandb_init.py:monkeypatch_ipython():581] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x000001FEE5208820>
2025-04-17 19:40:51,602 INFO    MainThread:19800 [wandb_init.py:init():781] calling init triggers
2025-04-17 19:40:51,602 INFO    MainThread:19800 [wandb_init.py:init():786] wandb.init called with sweep_config: {}
config: {'output_path': './training_outputs/', 'logger_uri': None, 'run_name': 'xttsv2_finetune_20250417_1940', 'project_name': 'XTTS-v2 Finetune', 'run_description': '\n        GPT XTTS training\n        ', 'print_step': 50, 'plot_step': 100, 'model_param_stats': False, 'wandb_entity': None, 'dashboard_logger': 'wandb', 'save_on_interrupt': True, 'log_model_step': 1000, 'save_step': 1000, 'save_n_checkpoints': 3, 'save_checkpoints': True, 'save_all_best': False, 'save_best_after': 0, 'target_loss': None, 'print_eval': True, 'test_delay_epochs': 0, 'run_eval': True, 'run_eval_steps': None, 'distributed_backend': 'nccl', 'distributed_url': 'tcp://localhost:54321', 'mixed_precision': False, 'precision': 'fp16', 'epochs': 1000, 'batch_size': 3, 'eval_batch_size': 3, 'grad_clip': 0.0, 'scheduler_after_epoch': True, 'lr': 5e-06, 'optimizer': 'AdamW', 'optimizer_params': {'betas': [0.9, 0.96], 'eps': 1e-08, 'weight_decay': 0.01}, 'lr_scheduler': 'MultiStepLR', 'lr_scheduler_params': {'milestones': [900000, 2700000, 5400000], 'gamma': 0.5, 'last_epoch': -1}, 'use_grad_scaler': False, 'allow_tf32': False, 'cudnn_enable': True, 'cudnn_deterministic': False, 'cudnn_benchmark': False, 'training_seed': 1, 'model': 'xtts', 'num_loader_workers': 0, 'num_eval_loader_workers': 0, 'use_noise_augment': False, 'audio': XttsAudioConfig(sample_rate=16000, output_sample_rate=24000, dvae_sample_rate=16000), 'use_phonemes': False, 'phonemizer': None, 'phoneme_language': None, 'compute_input_seq_cache': False, 'text_cleaner': None, 'enable_eos_bos_chars': False, 'test_sentences_file': '', 'phoneme_cache_path': None, 'characters': None, 'add_blank': False, 'batch_group_size': 48, 'loss_masking': None, 'min_audio_len': 1, 'max_audio_len': inf, 'min_text_len': 1, 'max_text_len': inf, 'compute_f0': False, 'compute_energy': False, 'compute_linear_spec': False, 'precompute_num_workers': 0, 'start_by_longest': False, 'shuffle': False, 'drop_last': False, 'datasets': [BaseDatasetConfig(formatter='', dataset_name='', path='', meta_file_train='', ignored_speakers=None, language='', phonemizer='', meta_file_val='', meta_file_attn_mask='')], 'test_sentences': [{'text': "It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.", 'speaker_wav': 'datasets/Buddhism For Beginners Plain and Simple - Discover Inner Peace - Free Buddha Full Length Audiobook/wavs/chunk_0007.wav', 'language': 'en'}, {'text': "This cake is great. It's so delicious and moist.", 'speaker_wav': 'datasets/Buddhism For Beginners Plain and Simple - Discover Inner Peace - Free Buddha Full Length Audiobook/wavs/chunk_0007.wav', 'language': 'en'}], 'eval_split_max_size': 256, 'eval_split_size': 0.01, 'use_speaker_weighted_sampler': False, 'speaker_weighted_sampler_alpha': 1.0, 'use_language_weighted_sampler': False, 'language_weighted_sampler_alpha': 1.0, 'use_length_weighted_sampler': False, 'length_weighted_sampler_alpha': 1.0, 'model_args': GPTArgs(gpt_batch_size=1, enable_redaction=False, kv_cache=True, gpt_checkpoint='', clvp_checkpoint=None, decoder_checkpoint=None, num_chars=255, tokenizer_file='./XTTS-files/vocab.json', gpt_max_audio_tokens=605, gpt_max_text_tokens=402, gpt_max_prompt_tokens=70, gpt_layers=30, gpt_n_model_channels=1024, gpt_n_heads=16, gpt_number_text_tokens=6681, gpt_start_text_token=261, gpt_stop_text_token=0, gpt_num_audio_tokens=1026, gpt_start_audio_token=1024, gpt_stop_audio_token=1025, gpt_code_stride_len=1024, gpt_use_masking_gt_prompt_approach=True, gpt_use_perceiver_resampler=True, input_sample_rate=22050, output_sample_rate=24000, output_hop_length=256, decoder_input_dim=1024, d_vector_dim=512, cond_d_vector_in_each_upsampling_layer=True, duration_const=102400, min_conditioning_length=66150, max_conditioning_length=143677, gpt_loss_text_ce_weight=0.01, gpt_loss_mel_ce_weight=1.0, debug_loading_failures=True, max_wav_length=255995, max_text_length=66150, mel_norm_file='./XTTS-files/mel_stats.pth', dvae_checkpoint='./XTTS-files/dvae.pth', xtts_checkpoint='./XTTS-files/model.pth', vocoder=''), 'model_dir': None, 'languages': ['en', 'es', 'fr', 'de', 'it', 'pt', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'hu', 'ko', 'ja', 'hi'], 'temperature': 0.85, 'length_penalty': 1.0, 'repetition_penalty': 2.0, 'top_k': 50, 'top_p': 0.85, 'num_gpt_outputs': 1, 'gpt_cond_len': 12, 'gpt_cond_chunk_len': 4, 'max_ref_len': 10, 'sound_norm_refs': False, 'optimizer_wd_only_on_weights': True, 'weighted_loss_attrs': None, 'weighted_loss_multipliers': None, '_initialized': True, 'num_chars': 255, '_wandb': {}}
2025-04-17 19:40:51,603 INFO    MainThread:19800 [wandb_init.py:init():809] starting backend
2025-04-17 19:40:51,603 INFO    MainThread:19800 [wandb_init.py:init():813] sending inform_init request
2025-04-17 19:40:51,620 INFO    MainThread:19800 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=spawn, using: spawn
2025-04-17 19:40:51,620 INFO    MainThread:19800 [wandb_init.py:init():823] backend started and connected
2025-04-17 19:40:51,623 INFO    MainThread:19800 [wandb_run.py:_label_probe_notebook():1267] probe notebook
2025-04-17 19:40:51,623 INFO    MainThread:19800 [wandb_run.py:_label_probe_notebook():1277] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2025-04-17 19:40:51,623 INFO    MainThread:19800 [wandb_init.py:init():915] updated telemetry
2025-04-17 19:40:51,663 INFO    MainThread:19800 [wandb_init.py:init():939] communicating run to backend with 90.0 second timeout
2025-04-17 19:40:52,395 INFO    MainThread:19800 [wandb_init.py:init():1014] starting run threads in backend
2025-04-17 19:40:52,538 INFO    MainThread:19800 [wandb_run.py:_console_start():2454] atexit reg
2025-04-17 19:40:52,538 INFO    MainThread:19800 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-04-17 19:40:52,538 INFO    MainThread:19800 [wandb_run.py:_redirect():2371] Wrapping output streams.
2025-04-17 19:40:52,538 INFO    MainThread:19800 [wandb_run.py:_redirect():2394] Redirects installed.
2025-04-17 19:40:52,543 INFO    MainThread:19800 [wandb_init.py:init():1056] run started, returning control to user process
2025-04-17 19:40:54,571 INFO    MainThread:19800 [jupyter.py:save_ipynb():384] [no run ID] not saving jupyter notebook
2025-04-17 19:40:54,571 INFO    MainThread:19800 [wandb_init.py:_pause_backend():546] [no run ID] pausing backend
2025-04-17 19:41:15,934 INFO    MainThread:19800 [wandb_init.py:_resume_backend():551] [no run ID] resuming backend
2025-04-17 20:33:47,421 INFO    MainThread:19800 [jupyter.py:save_ipynb():384] [no run ID] not saving jupyter notebook
2025-04-17 20:33:47,422 INFO    MainThread:19800 [wandb_init.py:_pause_backend():546] [no run ID] pausing backend
